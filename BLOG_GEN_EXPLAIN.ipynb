{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CRGtpnpwtrc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# langchain concepts\n",
        "1.Recursive Character text splitter\n",
        "2.Google Genarative AI embeddings\n",
        "3.faiss\n",
        "4.chatgooglegenarativeai\n",
        "5.load_qa_chain\n",
        "6.prompttemplate\n"
      ],
      "metadata": {
        "id": "s_5sOraNxR0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.faiss"
      ],
      "metadata": {
        "id": "wcPRrK-TyOQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.pdfreader\n",
        "# 2.streamlit\n",
        "# 3.langchain"
      ],
      "metadata": {
        "id": "G2xCMREyyX6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive Character text splitter --> text --> small chunks --> How the text is split: by list of characters.\n",
        "# How the chunk size is measured: by number of characters."
      ],
      "metadata": {
        "id": "BBVfTj8By-8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings --> Advanced word embedding techniques build on the foundational methods like Word2Vec, GloVe, and FastText by incorporating more sophisticated architectures and contextual information. Some of the most notable advanced techniques include embeddings generated by models like ELMo, BERT, and GPT. These techniques provide richer and more context-sensitive representations of words, improving performance on various NLP tasks."
      ],
      "metadata": {
        "id": "KAvWrUyNQB93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison of Techniques\n",
        "Technique\tArchitecture\tContext Sensitivity\tKey Advantage\n",
        "Word2Vec\tShallow neural network\tNo\tEfficient to train and simple\n",
        "GloVe\tGlobal matrix factorization\tNo\tCaptures global corpus statistics\n",
        "FastText\tShallow neural network\tNo\tConsiders subword information\n",
        "ELMo\tBidirectional LSTM\tYes\tContextual embeddings\n",
        "BERT\tTransformer (encoder)\tYes\tDeep bidirectional context\n",
        "GPT\tTransformer (decoder)\tYes (for generation)\tGenerative capabilities.\n"
      ],
      "metadata": {
        "id": "srvj26Z5QFai"
      }
    }
  ]
}